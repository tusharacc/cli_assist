# Lumos CLI Configuration

# OpenAI Configuration (Personal/External Use)
LLM_API_URL=https://api.openai.com/v1/chat/completions
LLM_API_KEY=sk-your-openai-api-key-here
LLM_REST_MODEL=gpt-3.5-turbo

# For GPT-4 (requires separate billing):
# LLM_REST_MODEL=gpt-4

# Anthropic Configuration (Alternative)
# LLM_API_URL=https://api.anthropic.com/v1/messages
# LLM_API_KEY=your-anthropic-api-key

# Enterprise LLM Configuration (Corporate Environment)
# ENTERPRISE_TOKEN_URL=https://your-enterprise.com/api/auth/token
# ENTERPRISE_CHAT_URL=https://your-enterprise.com/api/chat/completions
# ENTERPRISE_APP_ID=your-application-id
# ENTERPRISE_APP_KEY=your-application-key
# ENTERPRISE_APP_RESOURCE=your-app-resource-identifier
# ENTERPRISE_MODEL=enterprise-model-name

# Ollama Configuration (Local)
OLLAMA_URL=http://localhost:11434

# Backend Selection
# Options: auto, openai, enterprise, ollama
# auto = automatically choose best available backend
# openai = force OpenAI/REST API usage
# enterprise = force Enterprise LLM usage  
# ollama = force local Ollama usage
LUMOS_BACKEND=auto

# Other Settings
LUMOS_MODEL=devstral
LLM_EMBED_DB=.lumos_embeddings.db
LUMOS_BACKUP_DIR=.llm_backups